"""
Script de teste isolado para validar provedores LiteLLM.
Este arquivo √© usado para depura√ß√£o e valida√ß√£o de conectividade com cada provedor.
N√ÉO faz parte do fluxo principal de avalia√ß√£o.

Uso:
    python test_litellm_providers.py
"""

import os
import json
import logging
import time
from typing import Dict, Any, Optional
from dotenv import load_dotenv

# Importar litellm
try:
    from litellm import completion
    import litellm
except ImportError:
    print("‚ùå ERRO: litellm n√£o est√° instalado. Execute: pip install litellm>=1.79.3")
    exit(1)

# Carregar vari√°veis de ambiente
load_dotenv()

# Configura√ß√£o de logging
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class LiteLLMProviderTester:
    """Classe para testar provedores LiteLLM de forma isolada."""

    def __init__(self):
        """Inicializa o testador."""
        self.results = {}
        self.provider_configs = {
            "provider": {
                "model": "cerebras/llama-3.3-70b",
                "api_key_env": "CEREBRAS_API_KEY",
                "capabilities": ["json_mode", "streaming", "low_cost"],
            },
        }

    def check_api_key(self, provider: str) -> bool:
        """Verifica se a chave de API est√° configurada."""
        api_key_env = self.provider_configs[provider].get("api_key_env")
        if api_key_env is None:
            logger.error(f"‚ùå {provider.upper()}: Chave de API n√£o configurada no provider_configs")
            return False
        
        api_key = os.getenv(api_key_env)

        if not api_key:
            logger.error(f"‚ùå {provider.upper()}: Vari√°vel de ambiente '{api_key_env}' n√£o configurada")
            return False

        if api_key.strip() == "":
            logger.error(f"‚ùå {provider.upper()}: Chave de API vazia")
            return False

        logger.info(f"‚úÖ {provider.upper()}: Chave de API detectada")
        return True

    def test_provider_basic(self, provider: str) -> Optional[Dict[str, Any]]:
        """Testa connectividade b√°sica com um provedor."""
        logger.info(f"\n{'='*80}")
        logger.info(f"üß™ TESTE B√ÅSICO: {provider.upper()}")
        logger.info(f"{'='*80}\n")

        config = self.provider_configs.get(provider)
        if not config:
            logger.error(f"‚ùå Provedor '{provider}' n√£o configurado")
            return None

        # Verificar chave de API
        if not self.check_api_key(provider):
            return None

        model = config["model"]
        logger.info(f"üì¶ Modelo: {model}")
        logger.info(f"‚ú® Capacidades: {', '.join(config['capabilities'])}\n")

        try:
            logger.info(f"üöÄ Enviando teste b√°sico para '{model}'...")
            start_time = time.time()

            response = completion(
                model=model,
                messages=[
                    {
                        "role": "user",
                        "content": "Responda com exatamente: OK",
                    }
                ],
                max_tokens=10,
                temperature=0.1,
            )

            elapsed_time = time.time() - start_time

            # Extrair resposta
            response_any: Any = response
            content = (response_any.choices[0].message.content or "").strip()
            logger.info(f"‚úÖ SUCESSO em {elapsed_time:.2f}s")
            logger.info(f"üìù Resposta: '{content}'")

            return {
                "provider": provider,
                "model": model,
                "status": "success",
                "response": content,
                "latency": elapsed_time,
                "timestamp": time.time(),
            }

        except Exception as e:
            logger.error(f"‚ùå FALHA: {str(e)}")
            logger.exception("Exce√ß√£o completa:")
            return {
                "provider": provider,
                "model": model,
                "status": "failed",
                "error": str(e),
                "timestamp": time.time(),
            }

    def test_provider_json_mode(self, provider: str) -> Optional[Dict[str, Any]]:
        """Testa modo JSON (necess√°rio para AI Judge)."""
        logger.info(f"\n{'='*80}")
        logger.info(f"üß™ TESTE JSON MODE: {provider.upper()}")
        logger.info(f"{'='*80}\n")

        config = self.provider_configs.get(provider)
        if not config:
            logger.error(f"‚ùå Provedor '{provider}' n√£o configurado")
            return None

        if "json_mode" not in config.get("capabilities", []):
            logger.warning(f"‚ö†Ô∏è {provider.upper()} n√£o suporta JSON mode")
            return None

        model = config["model"]
        logger.info(f"üì¶ Modelo: {model}")
        logger.info(f"üéØ Testando resposta JSON estruturada...\n")

        try:
            logger.info(f"üöÄ Enviando teste JSON para '{model}'...")
            start_time = time.time()

            response = completion(
                model=model,
                messages=[
                    {
                        "role": "user",
                        "content": 'Responda com um JSON contendo: {"teste": "ok", "status": "funcionando"}',
                    }
                ],
                response_format={"type": "json_object"},
                max_tokens=100,
                temperature=0.1,
            )

            elapsed_time = time.time() - start_time

            # Extrair e parsear JSON
            response_any: Any = response
            content = (response_any.choices[0].message.content or "").strip()
            try:
                json_data = json.loads(content)
                logger.info(f"‚úÖ SUCESSO em {elapsed_time:.2f}s")
                logger.info(f"üìä JSON Parseado: {json.dumps(json_data, indent=2)}")

                return {
                    "provider": provider,
                    "model": model,
                    "status": "success",
                    "response": json_data,
                    "latency": elapsed_time,
                    "timestamp": time.time(),
                }

            except json.JSONDecodeError as je:
                logger.error(f"‚ùå Resposta n√£o √© JSON v√°lido: {je}")
                logger.error(f"üìù Conte√∫do recebido: {content}")
                return {
                    "provider": provider,
                    "model": model,
                    "status": "failed",
                    "error": f"JSON decode error: {str(je)}",
                    "raw_response": content,
                    "timestamp": time.time(),
                }

        except Exception as e:
            logger.error(f"‚ùå FALHA: {str(e)}")
            logger.exception("Exce√ß√£o completa:")
            return {
                "provider": provider,
                "model": model,
                "status": "failed",
                "error": str(e),
                "timestamp": time.time(),
            }

    def test_provider_streaming(self, provider: str) -> Optional[Dict[str, Any]]:
        """Testa streaming (adicional, n√£o cr√≠tico)."""
        logger.info(f"\n{'='*80}")
        logger.info(f"üß™ TESTE STREAMING: {provider.upper()}")
        logger.info(f"{'='*80}\n")

        config = self.provider_configs.get(provider)
        if not config:
            logger.error(f"‚ùå Provedor '{provider}' n√£o configurado")
            return None

        if "streaming" not in config.get("capabilities", []):
            logger.warning(f"‚ö†Ô∏è {provider.upper()} n√£o suporta streaming")
            return None

        model = config["model"]
        logger.info(f"üì¶ Modelo: {model}")
        logger.info(f"üéØ Testando streaming...\n")

        try:
            logger.info(f"üöÄ Iniciando stream para '{model}'...")
            start_time = time.time()

            response = completion(
                model=model,
                messages=[
                    {
                        "role": "user",
                        "content": "Conte at√© 3 rapidamente.",
                    }
                ],
                stream=True,
                max_tokens=50,
                temperature=0.1,
            )

            chunks_count = 0
            full_content = ""

            logger.info("üì® Recebendo chunks:\n")
            for chunk in response:
                chunk_any: Any = chunk
                if hasattr(chunk_any.choices[0].delta, 'content') and chunk_any.choices[0].delta.content:
                    content = chunk_any.choices[0].delta.content
                    full_content += content
                    chunks_count += 1
                    logger.info(f"  Chunk {chunks_count}: {content}")

            elapsed_time = time.time() - start_time
            logger.info(f"\n\n‚úÖ SUCESSO em {elapsed_time:.2f}s")
            logger.info(f"üìä Total de chunks: {chunks_count}")
            logger.info(f"üìù Conte√∫do completo: {full_content}")

            return {
                "provider": provider,
                "model": model,
                "status": "success",
                "chunks": chunks_count,
                "full_response": full_content,
                "latency": elapsed_time,
                "timestamp": time.time(),
            }

        except Exception as e:
            logger.error(f"‚ùå FALHA: {str(e)}")
            logger.exception("Exce√ß√£o completa:")
            return {
                "provider": provider,
                "model": model,
                "status": "failed",
                "error": str(e),
                "timestamp": time.time(),
            }

    def run_all_tests(self, provider: str, run_streaming: bool = False):
        """Executa todos os testes para um provedor."""
        logger.info(f"\n\n{'#'*80}")
        logger.info(f"# INICIANDO SUITE DE TESTES PARA: {provider.upper()}")
        logger.info(f"{'#'*80}\n")

        tests = [
            ("basic", self.test_provider_basic),
            ("json_mode", self.test_provider_json_mode),
        ]

        if run_streaming:
            tests.append(("streaming", self.test_provider_streaming))

        results = {}
        for test_name, test_func in tests:
            result = test_func(provider)
            results[test_name] = result

        # Resumo
        logger.info(f"\n\n{'='*80}")
        logger.info(f"üìä RESUMO DE TESTES: {provider.upper()}")
        logger.info(f"{'='*80}\n")

        passed = sum(1 for r in results.values() if r and r.get("status") == "success")
        failed = sum(1 for r in results.values() if r and r.get("status") == "failed")
        skipped = sum(1 for r in results.values() if r is None)

        logger.info(f"‚úÖ Passaram: {passed}/{len(tests)}")
        logger.info(f"‚ùå Falharam: {failed}/{len(tests)}")
        logger.info(f"‚äò Pulados: {skipped}/{len(tests)}\n")

        for test_name, result in results.items():
            if result:
                status_icon = "‚úÖ" if result.get("status") == "success" else "‚ùå"
                logger.info(f"{status_icon} {test_name.upper()}: {result.get('status', 'unknown')}")

        return results


def main():
    """Fun√ß√£o principal."""
    print("\n" + "="*80)
    print("üß™ LITELLM PROVIDERS TEST SUITE")
    print("="*80)
    print("""
Este script valida a conectividade e funcionalidades de cada provedor LiteLLM
antes de integra√ß√£o com o sistema de avalia√ß√£o RAG.

Testes executados:
  1. Teste B√°sico: Conectividade e resposta simples
  2. Teste JSON Mode: Modo JSON estruturado (cr√≠tico para AI Judge)
  3. Teste Streaming: Streaming de respostas (opcional)
""")
    print("="*80 + "\n")

    tester = LiteLLMProviderTester()

    # Testar Cerebras
    results = tester.run_all_tests("provider", run_streaming=False)

    # Relat√≥rio final
    print("\n" + "#"*80)
    print("# RELAT√ìRIO FINAL")
    print("#"*80 + "\n")

    all_success = all(
        r and r.get("status") == "success"
        for r in results.values()
    )

    if all_success:
        print("‚úÖ TODOS OS TESTES PASSARAM!")
        print("\nüéâ O provedor est√° pronto para integra√ß√£o com o AI Judge.\n")
        return 0
    else:
        print("‚ùå ALGUNS TESTES FALHARAM!")
        print("\n‚ö†Ô∏è Verifique os erros acima e configure as vari√°veis de ambiente.\n")
        return 1


if __name__ == "__main__":
    exit_code = main()
    exit(exit_code)
